package test

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"strings"
	"sync"
	"syscall"
	"testing"
	"time"

	"github.com/spf13/viper"

	"github.com/dagu-org/dagu/internal/cmn/config"
	"github.com/dagu-org/dagu/internal/cmn/fileutil"
	"github.com/dagu-org/dagu/internal/cmn/logger"
	"github.com/dagu-org/dagu/internal/core"
	exec1 "github.com/dagu-org/dagu/internal/core/exec"
	"github.com/dagu-org/dagu/internal/core/spec"
	"github.com/dagu-org/dagu/internal/persis/filedag"
	"github.com/dagu-org/dagu/internal/persis/filedagrun"
	"github.com/dagu-org/dagu/internal/persis/fileproc"
	"github.com/dagu-org/dagu/internal/persis/filequeue"
	"github.com/dagu-org/dagu/internal/persis/fileserviceregistry"
	runtimepkg "github.com/dagu-org/dagu/internal/runtime"
	"github.com/dagu-org/dagu/internal/runtime/agent"
	"github.com/google/uuid"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"gopkg.in/yaml.v3"
)

var setupLock sync.Mutex

const (
	latestStatusAssertTimeout  = 30 * time.Second
	latestStatusAssertInterval = 1 * time.Second
)

// HelperOption defines functional options for Helper
type HelperOption func(*Options)

type Options struct {
	CaptureLoggingOutput bool // CaptureLoggingOutput enables capturing of logging output
	DAGsDir              string
	ServerConfig         *config.Server
	ConfigMutators       []func(*config.Config)
	CoordinatorHost      string
	CoordinatorPort      int
	// Coordinator handler options for shared-nothing worker tests
	WithStatusPersistence bool // Enable status persistence via DAGRunStore
	WithLogPersistence    bool // Enable log persistence to filesystem
}

// WithCaptureLoggingOutput creates a logging capture option
func WithCaptureLoggingOutput() HelperOption {
	return func(opts *Options) {
		opts.CaptureLoggingOutput = true
	}
}

func WithDAGsDir(dir string) HelperOption {
	return func(opts *Options) {
		opts.DAGsDir = dir
	}
}

func WithServerConfig(cfg *config.Server) HelperOption {
	return func(opts *Options) {
		opts.ServerConfig = cfg
	}
}

// WithCoordinatorEnabled re-enables the coordinator in test configuration.
// By default, tests disable the coordinator since no coordinator is running.
func WithCoordinatorEnabled() HelperOption {
	return WithConfigMutator(func(cfg *config.Config) {
		cfg.Coordinator.Enabled = true
	})
}

// WithConfigMutator applies mutations to the loaded configuration after defaults are set.
func WithConfigMutator(mutator func(*config.Config)) HelperOption {
	return func(opts *Options) {
		opts.ConfigMutators = append(opts.ConfigMutators, mutator)
	}
}

// WithStatusPersistence enables status persistence via DAGRunStore on the coordinator handler.
// Use this for testing remote status pushing from workers.
func WithStatusPersistence() HelperOption {
	return func(opts *Options) {
		opts.WithStatusPersistence = true
	}
}

// WithLogPersistence enables log persistence to filesystem on the coordinator handler.
// Use this for testing remote log streaming from workers.
func WithLogPersistence() HelperOption {
	return func(opts *Options) {
		opts.WithLogPersistence = true
	}
}

// Setup creates and returns a Helper preconfigured for tests.
//
// Setup prepares an isolated test environment: it creates a temporary DAGU_HOME, writes a minimal config file, initializes stores and a runtime manager, sets key environment variables (e.g. DEBUG, CI, TZ, DAGU_EXECUTABLE, DAGU_CONFIG, SHELL), installs a cancellable context, and registers cleanup to restore the working directory and remove the temp directory. Use the returned Helper to interact with the test runtime and stores.
func Setup(t *testing.T, opts ...HelperOption) Helper {
	setupLock.Lock()
	defer setupLock.Unlock()

	// Save the original working directory and restore it after the test.
	// This is important because some tests (via agent) may change the working
	// directory to a temp directory that gets cleaned up, which would cause
	// subsequent tests to fail when they call os.Getwd().
	origWD, err := os.Getwd()
	if err == nil {
		t.Cleanup(func() {
			_ = os.Chdir(origWD)
		})
	}

	var options Options
	for _, opt := range opts {
		opt(&options)
	}

	// Set the log level to debug
	_ = os.Setenv("DEBUG", "true")

	// Set the CI flag
	_ = os.Setenv("CI", "true")
	_ = os.Setenv("TZ", "UTC")

	random := uuid.New().String()
	tmpDir := fileutil.MustTempDir(fmt.Sprintf("dagu-test-%s", random))
	require.NoError(t, os.Setenv("DAGU_HOME", tmpDir))

	root := getProjectRoot(t)
	executablePath := filepath.Join(root, ".local", "bin", "dagu")
	if runtime.GOOS == "windows" {
		executablePath += ".exe"
	}

	_ = os.Setenv("DAGU_EXECUTABLE", executablePath)

	// on Windows, set SHELL to powershell
	if runtime.GOOS == "windows" {
		powershellPath, err := exec.LookPath("powershell")
		require.NoError(t, err, "failed to find powershell in PATH")
		require.NoError(t, os.Setenv("SHELL", powershellPath))
	}

	ctx := createDefaultContext()
	// Use a fresh viper instance to avoid any global state issues between tests.
	v := viper.New()
	loader := config.NewConfigLoader(v)
	cfg, loadErr := loader.Load()
	require.NoError(t, loadErr)

	cfg.Core.TZ = "UTC"
	cfg.Core.Location = time.UTC
	cfg.Core.TzOffsetInSec = 0
	cfg.Paths.Executable = executablePath
	cfg.Paths.LogDir = filepath.Join(tmpDir, "logs")
	dataDir := filepath.Join(tmpDir, "data")
	cfg.Paths.DataDir = dataDir
	cfg.Paths.DAGRunsDir = filepath.Join(dataDir, "dag-runs")
	cfg.Paths.QueueDir = filepath.Join(dataDir, "queue")
	cfg.Paths.ProcDir = filepath.Join(dataDir, "proc")
	cfg.Paths.ServiceRegistryDir = filepath.Join(dataDir, "service-registry")
	cfg.Paths.UsersDir = filepath.Join(dataDir, "users")
	cfg.Paths.SuspendFlagsDir = filepath.Join(tmpDir, "suspend-flags")
	cfg.Paths.AdminLogsDir = filepath.Join(tmpDir, "admin-logs")
	cfg.Coordinator.Enabled = false
	if options.DAGsDir != "" {
		cfg.Paths.DAGsDir = options.DAGsDir
	}

	if options.ServerConfig != nil {
		cfg.Server = *options.ServerConfig
	}
	for _, mutate := range options.ConfigMutators {
		mutate(cfg)
	}

	if options.CoordinatorHost != "" {
		cfg.Coordinator.Host = options.CoordinatorHost
	}
	if options.CoordinatorPort != 0 {
		cfg.Coordinator.Port = options.CoordinatorPort
	}

	configFile := filepath.Join(tmpDir, "config.yaml")
	writeHelperConfigFile(t, cfg, configFile)
	cfg.Paths.ConfigFileUsed = configFile
	_ = os.Setenv("DAGU_CONFIG", configFile)

	ctx = config.WithConfig(ctx, cfg)

	dagStore := filedag.New(cfg.Paths.DAGsDir, filedag.WithFlagsBaseDir(cfg.Paths.SuspendFlagsDir), filedag.WithSkipExamples(true))
	runStore := filedagrun.New(cfg.Paths.DAGRunsDir)
	procStore := fileproc.New(cfg.Paths.ProcDir)
	queueStore := filequeue.New(cfg.Paths.QueueDir)
	serviceMonitor := fileserviceregistry.New(cfg.Paths.ServiceRegistryDir)

	drm := runtimepkg.NewManager(runStore, procStore, cfg)

	helper := Helper{
		Context:         ctx,
		Config:          cfg,
		DAGRunMgr:       drm,
		DAGStore:        dagStore,
		DAGRunStore:     runStore,
		ProcStore:       procStore,
		QueueStore:      queueStore,
		ServiceRegistry: serviceMonitor,
		SubCmdBuilder:   runtimepkg.NewSubCmdBuilder(cfg),

		tmpDir: tmpDir,
	}

	if options.CaptureLoggingOutput {
		helper.LoggingOutput = &SyncBuffer{buf: new(bytes.Buffer)}
		loggerInstance := logger.NewLogger(
			logger.WithDebug(),
			logger.WithFormat("text"),
			logger.WithWriter(helper.LoggingOutput),
		)
		helper.Context = logger.WithFixedLogger(helper.Context, loggerInstance)
	}

	ctx, cancel := context.WithCancel(helper.Context)
	helper.Context = ctx
	helper.Cancel = cancel

	// setup the default shell for reproducible result
	if runtime.GOOS == "windows" {
		// On Windows, try PowerShell first, then cmd
		if _, err := exec.LookPath("powershell"); err == nil {
			setShell(t, "powershell")
		} else if _, err := exec.LookPath("cmd"); err == nil {
			setShell(t, "cmd")
		} else {
			t.Fatal("No suitable shell found on Windows")
		}
	} else {
		setShell(t, "sh")
	}

	t.Cleanup(helper.Cleanup)
	return helper
}

// writeHelperConfigFile writes a minimal YAML configuration to configPath so subprocesses can rely on a stable --config file.
// The written file contains core settings (debug, log format, default shell, and tz if set), paths, and any enabled or configured
// queues, scheduler, coordinator, worker, and ui sections derived from cfg.
// The function fails the test if YAML marshaling or writing the file returns an error.
func writeHelperConfigFile(t *testing.T, cfg *config.Config, configPath string) {
	t.Helper()

	configData := map[string]any{
		"debug":         cfg.Core.Debug,
		"log_format":    cfg.Core.LogFormat,
		"default_shell": cfg.Core.DefaultShell,
	}
	if cfg.Core.TZ != "" {
		configData["tz"] = cfg.Core.TZ
	}

	configData["paths"] = map[string]any{
		"dags_dir":             cfg.Paths.DAGsDir,
		"log_dir":              cfg.Paths.LogDir,
		"data_dir":             cfg.Paths.DataDir,
		"suspend_flags_dir":    cfg.Paths.SuspendFlagsDir,
		"admin_logs_dir":       cfg.Paths.AdminLogsDir,
		"base_config":          cfg.Paths.BaseConfig,
		"dag_runs_dir":         cfg.Paths.DAGRunsDir,
		"queue_dir":            cfg.Paths.QueueDir,
		"proc_dir":             cfg.Paths.ProcDir,
		"service_registry_dir": cfg.Paths.ServiceRegistryDir,
		"users_dir":            cfg.Paths.UsersDir,
		"executable":           cfg.Paths.Executable,
	}

	if cfg.Queues.Enabled || len(cfg.Queues.Config) > 0 {
		qcfg := map[string]any{
			"enabled": cfg.Queues.Enabled,
		}
		if len(cfg.Queues.Config) > 0 {
			var configs []map[string]any
			for _, q := range cfg.Queues.Config {
				entry := map[string]any{"name": q.Name}
				if q.MaxActiveRuns > 0 {
					entry["max_active_runs"] = q.MaxActiveRuns
				}
				configs = append(configs, entry)
			}
			if len(configs) > 0 {
				qcfg["config"] = configs
			}
		}
		configData["queues"] = qcfg
	}

	scheduler := map[string]any{}
	// Always write port so that 0 (disable health server) is preserved when loading
	scheduler["port"] = cfg.Scheduler.Port
	if cfg.Scheduler.LockStaleThreshold > 0 {
		scheduler["lock_stale_threshold"] = cfg.Scheduler.LockStaleThreshold.String()
	}
	if cfg.Scheduler.LockRetryInterval > 0 {
		scheduler["lock_retry_interval"] = cfg.Scheduler.LockRetryInterval.String()
	}
	if cfg.Scheduler.ZombieDetectionInterval >= 0 {
		scheduler["zombie_detection_interval"] = cfg.Scheduler.ZombieDetectionInterval.String()
	}
	if len(scheduler) > 0 {
		configData["scheduler"] = scheduler
	}

	coordData := map[string]any{
		"enabled": cfg.Coordinator.Enabled,
	}
	if cfg.Coordinator.Host != "" {
		coordData["host"] = cfg.Coordinator.Host
	}
	if cfg.Coordinator.Advertise != "" {
		coordData["advertise"] = cfg.Coordinator.Advertise
	}
	if cfg.Coordinator.Port != 0 {
		coordData["port"] = cfg.Coordinator.Port
	}
	configData["coordinator"] = coordData

	if cfg.Worker.ID != "" || cfg.Worker.MaxActiveRuns != 0 || len(cfg.Worker.Labels) > 0 {
		configData["worker"] = map[string]any{
			"id":              cfg.Worker.ID,
			"max_active_runs": cfg.Worker.MaxActiveRuns,
			"labels":          cfg.Worker.Labels,
		}
	}

	ui := map[string]any{}
	if cfg.UI.LogEncodingCharset != "" {
		ui["log_encoding_charset"] = cfg.UI.LogEncodingCharset
	}
	if cfg.UI.NavbarColor != "" {
		ui["navbar_color"] = cfg.UI.NavbarColor
	}
	if cfg.UI.NavbarTitle != "" {
		ui["navbar_title"] = cfg.UI.NavbarTitle
	}
	if cfg.UI.MaxDashboardPageLimit != 0 {
		ui["max_dashboard_page_limit"] = cfg.UI.MaxDashboardPageLimit
	}
	if cfg.UI.DAGs.SortField != "" || cfg.UI.DAGs.SortOrder != "" {
		ui["dags"] = map[string]any{
			"sort_field": cfg.UI.DAGs.SortField,
			"sort_order": cfg.UI.DAGs.SortOrder,
		}
	}
	if len(ui) > 0 {
		configData["ui"] = ui
	}

	// Always write auth section so subprocesses use the same auth mode.
	// Without this, subprocesses would default to "builtin" and auto-generate
	// a different token secret, causing authentication mismatches.
	authMode := string(cfg.Server.Auth.Mode)
	if authMode == "" {
		authMode = "none"
	}
	authData := map[string]any{
		"mode": authMode,
	}
	if cfg.Server.Auth.Builtin.Token.Secret != "" {
		authData["builtin"] = map[string]any{
			"token": map[string]any{
				"secret": cfg.Server.Auth.Builtin.Token.Secret,
			},
		}
	}
	if cfg.Server.Auth.Basic.Username != "" {
		authData["basic"] = map[string]any{
			"username": cfg.Server.Auth.Basic.Username,
			"password": cfg.Server.Auth.Basic.Password,
		}
	}
	configData["auth"] = authData

	content, err := yaml.Marshal(configData)
	require.NoError(t, err)
	require.NoError(t, os.WriteFile(configPath, content, 0600))
}

// Helper provides test utilities and configuration
type Helper struct {
	Context         context.Context
	Cancel          context.CancelFunc
	Config          *config.Config
	LoggingOutput   *SyncBuffer
	DAGStore        exec1.DAGStore
	DAGRunStore     exec1.DAGRunStore
	DAGRunMgr       runtimepkg.Manager
	ProcStore       exec1.ProcStore
	QueueStore      exec1.QueueStore
	ServiceRegistry exec1.ServiceRegistry
	SubCmdBuilder   *runtimepkg.SubCmdBuilder

	tmpDir string
}

// Cleanup removes temporary test directories
func (h Helper) Cleanup() {
	if h.Cancel != nil {
		h.Cancel()
	}
	_ = os.RemoveAll(h.tmpDir)
}

// TempFile creates a temp file with specified name and content.
func (h Helper) TempFile(t *testing.T, name string, data []byte) string {
	t.Helper()

	filename := filepath.Join(h.tmpDir, name)
	err := os.WriteFile(filename, data, 0600)
	require.NoError(t, err)
	return filename
}

// DAG creates a test DAG from YAML content
func (h Helper) DAG(t *testing.T, yamlContent string) DAG {
	t.Helper()

	err := os.MkdirAll(h.Config.Paths.DAGsDir, 0750)
	require.NoError(t, err, "failed to create DAGs directory %q", h.Config.Paths.DAGsDir)

	// Generate a unique filename for the test DAG
	filename := fmt.Sprintf("%s.yaml", uuid.New().String())
	testFile := filepath.Join(h.Config.Paths.DAGsDir, filename)
	err = os.WriteFile(testFile, []byte(yamlContent), 0600)
	require.NoError(t, err, "failed to write test DAG")

	dag, err := spec.Load(h.Context, testFile)
	require.NoError(t, err, "failed to load test DAG")

	return DAG{
		Helper: &h,
		DAG:    dag,
	}
}

// CreateDAGFile creates a DAG file in a given directory for tests that need separate DAG files
func (h Helper) CreateDAGFile(t *testing.T, dir string, name string, yamlContent []byte) string {
	t.Helper()

	// Create the directory if it doesn't exist
	err := os.MkdirAll(dir, 0750)
	require.NoError(t, err, "failed to create directory %q", dir)

	if !fileutil.IsYAMLFile(name) {
		name = fmt.Sprintf("%s.yaml", name)
	}

	dagFile := filepath.Join(dir, name)
	err = os.WriteFile(dagFile, yamlContent, 0600)
	require.NoError(t, err, "failed to write DAG file %q", name)

	t.Cleanup(func() { _ = os.Remove(dagFile) })

	return dagFile
}

func (h Helper) DAGExpectError(t *testing.T, name string, expectedErr string) {
	t.Helper()

	filePath := TestdataPath(t, name)
	_, err := spec.Load(h.Context, filePath)
	require.Error(t, err, "expected error loading test DAG %q", name)
	require.Contains(t, err.Error(), expectedErr, "expected error %q, got %q", expectedErr, err.Error())
}

type DAG struct {
	*Helper
	*core.DAG
}

func (d *DAG) AssertLatestStatus(t *testing.T, expected core.Status) {
	t.Helper()

	require.Eventually(t, func() bool {
		latest, err := d.DAGRunMgr.GetLatestStatus(d.Context, d.DAG)
		if err != nil {
			return false
		}
		t.Logf("latest status=%s errors=%v", latest.Status.String(), latest.Errors())
		return latest.Status == expected
	}, latestStatusAssertTimeout, latestStatusAssertInterval)
}

func (d *DAG) AssertDAGRunCount(t *testing.T, expected int) {
	t.Helper()

	// the +1 to the limit is needed to ensure that the number of dag-run
	// entries is exactly the expected number
	runstore := d.DAGRunMgr.ListRecentStatus(d.Context, d.Name, expected+1)
	require.Len(t, runstore, expected)
}

func (d *DAG) AssertCurrentStatus(t *testing.T, expected core.Status) {
	t.Helper()

	assert.Eventually(t, func() bool {
		curr, _ := d.DAGRunMgr.GetCurrentStatus(d.Context, d.DAG, "")
		if curr == nil {
			return false
		}
		t.Logf("current status=%s errors=%v", curr.Status.String(), curr.Errors())
		return curr.Status == expected
	}, time.Second*5, time.Second)
}

// AssertOutputs checks the given outputs against the actual outputs of the DAG
// Note that this function does not respect dependencies between nodes
// making the outputs with the same key indeterministic
func (d *DAG) AssertOutputs(t *testing.T, outputs map[string]any) {
	t.Helper()

	status, err := d.DAGRunMgr.GetLatestStatus(d.Context, d.DAG)
	require.NoError(t, err)

	// collect the actual outputs from the status
	var actualOutputs = make(map[string]string)
	for _, node := range status.Nodes {
		if node.OutputVariables == nil {
			continue
		}
		value, ok := node.OutputVariables.Load(node.Step.Output)
		if ok {
			actualOutputs[node.Step.Output] = value.(string)
		}
	}

	// compare the actual outputs with the expected outputs
	for key, expected := range outputs {
		if expected == "" {
			_, ok := actualOutputs[key]
			assert.False(t, ok, "expected output %q to be empty", key)
			continue
		}

		if actual, ok := actualOutputs[key]; ok {
			switch expected := expected.(type) {
			case string:
				assert.Equal(t, fmt.Sprintf("%s=%s", key, expected), actual)

			case Contains:
				assert.Contains(t, actual, string(expected), "expected output %q to include %q", key, expected)

			case []Contains:
				for _, c := range expected {
					assert.Contains(t, actual, string(c), "expected output %q to include %q", key, c)
				}

			case NotEmpty:
				_, value, found := strings.Cut(actual, "=")
				assert.True(t, found, "expected output %q to be in the form key=value", key)
				assert.NotEmpty(t, value, "expected output %q to be not empty", key)

			default:
				t.Errorf("unsupported value matcher type %T", expected)

			}
		} else {
			t.Errorf("expected output %q not found", key)
		}
	}
}

// ReadOutputs reads the collected outputs from the outputs.json file.
func (d *DAG) ReadOutputs(t *testing.T) map[string]string {
	t.Helper()

	dagRunsDir := d.Config.Paths.DAGRunsDir
	dagRunDir := filepath.Join(dagRunsDir, d.Name, "dag-runs")

	var outputsPath string
	_ = filepath.Walk(dagRunDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if info.Name() == filedagrun.OutputsFile {
			outputsPath = path
			return filepath.SkipAll
		}
		return nil
	})

	if outputsPath == "" {
		return nil
	}

	data, err := os.ReadFile(outputsPath) //nolint:gosec // path is constructed from test config
	require.NoError(t, err)

	var outputs exec1.DAGRunOutputs
	require.NoError(t, json.Unmarshal(data, &outputs))

	return outputs.Outputs
}

type NotEmpty struct{}

type Contains string

type AgentOption func(*Agent)

func WithAgentOptions(options agent.Options) AgentOption {
	return func(a *Agent) {
		a.opts = options
	}
}

func WithDAGRunID(dagRunID string) AgentOption {
	return func(a *Agent) {
		a.dagRunID = dagRunID
	}
}

func (d *DAG) Agent(opts ...AgentOption) *Agent {
	helper := &Agent{Helper: d.Helper, DAG: d.DAG}

	for _, opt := range opts {
		opt(helper)
	}

	var dagRunID string
	if helper.opts.RetryTarget != nil {
		dagRunID = helper.opts.RetryTarget.DAGRunID
	} else if helper.dagRunID != "" {
		dagRunID = helper.dagRunID
	} else {
		dagRunID = genDAGRunID()
	}

	logDir := d.Config.Paths.LogDir
	logFile := filepath.Join(d.Config.Paths.LogDir, dagRunID+".log")
	root := exec1.NewDAGRunRef(d.Name, dagRunID)

	helper.opts.DAGRunStore = d.DAGRunStore
	helper.opts.ServiceRegistry = d.ServiceRegistry
	helper.opts.RootDAGRun = root
	helper.opts.PeerConfig = d.Config.Core.Peer
	helper.opts.DefaultExecMode = d.Config.DefaultExecMode

	helper.Agent = agent.New(
		dagRunID,
		d.DAG,
		logDir,
		logFile,
		d.DAGRunMgr,
		d.DAGStore,
		helper.opts,
	)

	return helper
}

type Agent struct {
	*Helper
	*core.DAG
	*agent.Agent
	opts     agent.Options
	dagRunID string // the dag-run ID for this agent
}

func (a *Agent) RunError(t *testing.T) {
	t.Helper()

	err := a.Run(a.Context)
	assert.Error(t, err)

	st := a.Status(a.Context).Status
	require.Equal(t, core.Failed.String(), st.String())
}

func (a *Agent) RunCancel(t *testing.T) {
	t.Helper()

	proc, err := a.ProcStore.Acquire(a.Context, a.ProcGroup(), exec1.DAGRunRef{
		Name: a.Name,
		ID:   a.dagRunID,
	})
	require.NoError(t, err, "failed to acquire proc")
	t.Cleanup(func() {
		_ = proc.Stop(a.Context)
	})

	err = a.Run(a.Context)
	assert.NoError(t, err)

	st := a.Status(a.Context).Status
	require.Equal(t, core.Aborted.String(), st.String())
}

func (a *Agent) RunCheckErr(t *testing.T, expectedErr string) {
	t.Helper()

	err := a.Run(a.Context)
	require.Error(t, err, "expected error %q, got nil", expectedErr)
	require.Contains(t, err.Error(), expectedErr)
	st := a.Status(a.Context)
	require.Equal(t, core.Failed.String(), st.Status.String())
}

func (a *Agent) RunSuccess(t *testing.T) {
	t.Helper()

	err := a.Run(a.Context)
	assert.NoError(t, err, "failed to run agent")

	st := a.Status(a.Context).Status
	require.Equal(t, core.Succeeded.String(), st.String(), "expected status %q, got %q", core.Succeeded, st)

	// check all nodes are in success or skipped state
	for _, node := range a.Status(a.Context).Nodes {
		st := node.Status
		if st == core.NodeSkipped || st == core.NodeSucceeded {
			continue
		}
		t.Errorf("expected node %q to be in success state, got %q", node.Step.Name, st.String())
	}
}

func (a *Agent) Abort() {
	a.Signal(a.Context, syscall.SIGTERM)
}

// SyncBuffer provides thread-safe buffer operations
type SyncBuffer struct {
	buf  *bytes.Buffer
	lock sync.Mutex
}

func (b *SyncBuffer) Write(p []byte) (n int, err error) {
	b.lock.Lock()
	defer b.lock.Unlock()
	return b.buf.Write(p)
}

func (b *SyncBuffer) String() string {
	b.lock.Lock()
	defer b.lock.Unlock()
	return b.buf.String()
}

func (b *SyncBuffer) Reset() {
	b.lock.Lock()
	defer b.lock.Unlock()
	b.buf.Reset()
}

// createDefaultContext creates a context with default logger settings
func createDefaultContext() context.Context {
	ctx := context.Background()
	return logger.WithLogger(ctx, logger.NewLogger(
		logger.WithDebug(),
		logger.WithFormat("text"),
	))
}

// getShell returns the path to the default shell.
func setShell(t *testing.T, shell string) {
	t.Helper()

	shPath, err := exec.LookPath(shell)
	require.NoError(t, err, "failed to find shell")
	_ = os.Setenv("SHELL", shPath)
}

// genDAGRunID generates a new unique dag-run ID using UUID v7.
func genDAGRunID() string {
	id, err := uuid.NewV7()
	if err != nil {
		panic(err)
	}
	return id.String()
}

// TestdataPath returns the path to a testdata file.
func TestdataPath(t *testing.T, filename string) string {
	t.Helper()

	rootDir := getProjectRoot(t)

	return filepath.Join(rootDir, "internal", "testdata", filepath.Clean(filename))
}

// ReadTestdata reads the content of a testdata file.
func ReadTestdata(t *testing.T, filename string) []byte {
	t.Helper()

	path := TestdataPath(t, filename)
	data, err := os.ReadFile(path) //nolint:gosec
	require.NoError(t, err, "failed to read testdata file %q", filename)

	return data
}

// getProjectRoot returns the root directory of the project.
// This allows to read testdata files from the testdata directory.
func getProjectRoot(t *testing.T) string {
	t.Helper()

	_, filename, _, ok := runtime.Caller(1)
	require.True(t, ok, "failed to get caller information")
	rootDir := filepath.Join(filepath.Dir(filename), "..", "..")

	return filepath.Clean(rootDir)
}
